# -*- coding: utf-8 -*-
"""Predictive Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L1vLh4piCI0ZwYpfdVaHj0_CWf2QgyuT

# **1. Import Library**
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report
from sklearn.model_selection import GridSearchCV

"""# **2. Data Loading**

Untuk dapat mengambil dataset dari Kaggle, perlu dilakukan konfigurasi kredensial API Kaggle di Google Colab. Kaggle menyediakan API yang memungkinkan akses langsung ke dataset mereka tanpa perlu mengunduhnya secara manual.

Proses ini dilakukan dengan mengunggah file kaggle.json yang berisi kredensial API yang diunduh dari halaman akun Kaggle.
"""

# Import module yang disediakan google colab untuk kebutuhan upload file
from google.colab import files
files.upload()

# Hapus semua folder yang berpotensi bentrok
!rm -rf "anemia-dataset.zip"
!rm -rf "anemia.csv"

# Setup kredensial Kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download dataset Anemia Dataset
!kaggle datasets download -d biswaranjanrao/anemia-dataset

# Unzip file dataset
!unzip anemia-dataset.zip

"""Dengan kredensial yang telah disiapkan, kode *!kaggle datasets download -d biswaranjanrao/anemia-dataset* digunakan untuk mengunduh dataset yang berjudul "anemia-dataset" dari Kaggle.

Setelah itu, file yang diunduh (dalam format ZIP) diekstrak menggunakan perintah *!unzip anemia-dataset.zip*. Ekstraksi ini bertujuan untuk mengakses file data dalam format CSV yang ada di dalamnya.

Setelah itu, kita perlu mengubah dataset yang diunduh dalam format CSV ke dalam variabel DataFrame.
"""

# Membaca dataset
df = pd.read_csv("anemia.csv")
df.head()

"""# **3. Data Understanding**

Selanjutnya, cek informasi pada dataset dengan fungsi info()
"""

# Menampilkan informasi tentang dataset
df.info()

"""Dari hasil *df.info()* dapat dilihat bahwa dataset terdiri dari 1421 baris dan 6 kolom. Detail tiap kolom:
- Gender : merupakan jenis kelamin individu (0 = Laki-laki, 1 = Perempuan).
- Hemoglobin : merupakan kadar hemoglobin (protein) dalam sel darah merah.
- MCH : *Mean Corpuscular Hemoglobin* merupakan jumlah rata-rata hemoglobin di dalam satu sel darah merah.
- MCHC : *Mean Corpuscular Hemoglobin Concentration* merupakan konsentrasi rata-rata hemoglobin dalam satu sel darah merah.
- MCV : *Mean Corpuscular Volume* merupakan volume rata-rata sel darah merah.
- Results : merupakan label yang menunjukkan individu menderita anemia atau tidak (0 = Tidak anemia, 1 = Anemia), result adalah fitur target

Semua kolom bertipe data numerik dengan 4 fitur bertipe data float64 (Hemoglobin, MCH, MCHC, dan MCV) dan 2 fitur bertipe data int64 (Gender dan Result). Uraian di atas menunjukkan bahwa setiap kolom telah memiliki tipe data yang sesuai dan dikarenakan semua fitur adalah numerik, maka tidak diperlukan encoding untuk pelatihan.

Selanjutnya, dilakukan pengecekan deskripsi statistik data dengan fitur describe().
"""

# Menampilkan statistik deskriptif dari dataset untuk kolom numerik
df.describe()

"""Kolom Gender dan Result memiliki distribusi yang cukup seimbang, sementara kolom numerik seperti Hemoglobin, MCH, MCHC, dan MCV menunjukkan variasi yang cukup besar. Variasi yang besar pada kolom Hemoglobin, MCH, MCHC, dan MCV adalah hal yang wajar, mengingat perbedaan kondisi antara individu yang menderita anemia dan yang tidak.

Selanjutnya kita memeriksa apakah ada missing value.
"""

# Memeriksa missing value
df.isnull().sum()

"""Tidak ada missing value untuk setiap kolom sehingga tidak diperlukan penanganan missing value

Setelah itu, kita periksa apakah ada data yang duplikat
"""

# Memeriksa duplikasi data
jumlah_duplikat = df.duplicated().sum()
print(f"Jumlah baris duplikat: {jumlah_duplikat}")

"""Terdapat 887 baris duplikat pada dataset yang harus dihapus

Selanjutnya, kita cek apakah ada outliers
"""

# Menyiapkan kolom yang akan dianalisis (semua kolom numerik)
numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns

# Deteksi outlier dengan IQR
Q1 = df[numeric_columns].quantile(0.25)
Q3 = df[numeric_columns].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Menentukan jumlah outlier untuk setiap kolom
outliers = ((df[numeric_columns] < lower_bound) | (df[numeric_columns] > upper_bound)).sum()

# Menampilkan jumlah outlier per kolom
print("Jumlah Outlier per Kolom:")
print(outliers)

# Menentukan jumlah baris dan kolom untuk visualisasi (3 kolom)
n_cols = 3
n_rows = (len(numeric_columns) // n_cols) + (len(numeric_columns) % n_cols > 0)  # Menyesuaikan jumlah baris

# Set canvas ukuran untuk visualisasi
plt.figure(figsize=(n_cols * 6, n_rows * 4))  # Menyesuaikan ukuran figure

# Membuat boxplot untuk setiap kolom numerik
for i, col in enumerate(numeric_columns):
    plt.subplot(n_rows, n_cols, i + 1)  # Membuat grid dengan jumlah baris dan kolom yang disesuaikan
    sns.boxplot(y=df[col])
    plt.title(f"Boxplot untuk {col}")
    plt.xlabel(col)

# Menampilkan plot
plt.tight_layout()
plt.show()

"""Berdasarkan hasil dari perhitungan outlier menggunakan metode Interquartile Range (IQR), hanya ada satu outlier pada kadar hemoglobin, dan kadar hemoglobin memang bervariasi antar individu, terutama dalam konteks mendeteksi anemia. Mengingat bahwa kadar hemoglobin yang ekstrem dapat mencerminkan kondisi medis tertentu, mempertahankan outlier tersebut sangat penting karena dapat memberikan informasi diagnostik yang berharga dan membantu model dalam mendeteksi kondisi medis yang jarang terjadi.

# **3. Exploratory Data Analysis**

Selanjutnya, kita akan melakukan proses analisis data dengan teknik Univariate, Bivariate, dan Multivariate Analysis.

## **Univariate Analysis**

Fitur Gender dan Result diubah menjadi data kategorikal untuk mempermudah proses EDA
"""

# Mengubah nilai di DataFrame untuk Gender dan Result menjadi kategorikal
df['Gender'] = df['Gender'].replace({0: 'Male', 1: 'Female'})
df['Result'] = df['Result'].replace({0: 'Not Anemic', 1: 'Anemic'})

"""Kita akan melakukan analisis terhadap fitur kategorikal terlebih dahulu

### **Analisis Distribusi Data Kategorikal**
"""

# Pilih kolom kategorikal yang akan dianalisis
categorical_columns = ['Gender', 'Result']

# Set plot size
plt.figure(figsize=(12, 8))

# Buat bar plot horizontal untuk setiap variabel kategorikal
for i, col in enumerate(categorical_columns, 1):
    plt.subplot(2, 2, i)
    if col == 'Gender':
        # Plot untuk Gender dengan warna yang berbeda
        sns.countplot(data=df, y=col, palette=['#B71C1C', '#1976D2'], order=df[col].value_counts().index, hue='Gender')
    else:
        # Plot untuk Result dengan warna yang berbeda
        sns.countplot(data=df, y=col, palette=['#1976D2', '#B71C1C'], order=df[col].value_counts().index, hue='Result')

    plt.title(f"Distribusi {col}")

# Menampilkan plot
plt.tight_layout()
plt.show()

"""Dari hasil, dapat dilihat bahwa terdapat lebih banyak individu berjenis kelamin Female daripada Male, dengan jumlah Female yang jauh lebih dominan. Distribusi Result menunjukkan bahwa kategori Not Anemic lebih dominan dibandingkan dengan Anemic, dengan jumlah individu yang tidak menderita anemia jauh lebih banyak.

Selanjutnya, lakukan analisis terhadap data numerik

### **Analisis Distribusi Data Numerik**
"""

# Menyiapkan kolom yang akan dianalisis
colhist = df.iloc[:, 1:5]  # Kolom dari Hemoglobin, MCH, MCHC, MCV

# Membuat histogram untuk masing-masing kolom dengan menggunakan .hist() dari pandas
colhist.hist(bins=50, figsize=(20, 5), layout=(1, 4))

# Menambahkan judul utama
plt.suptitle("Analisis Distribusi Histogram")

# Menampilkan plot
plt.show()

"""Dari histogram di atas, dapat dilihat bahwa Hemoglobin cenderung terdistribusi dengan lonjakan di sekitar 16 (cenderung left-skewed). MCH memiliki distribusi yang lebih merata dengan puncak di kisaran 20-22, sementara MCHC lebih terkonsentrasi pada nilai antara 28-32. MCV menunjukkan variasi yang lebih luas, terutama di kisaran 70 hingga 100.

## **Bivariate Analysis**

Selanjutnya, kita akan menganalisis hubungan antara fitur-fitur terhadap fitur target (Result)
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set ukuran canvas untuk 1 baris, 4 kolom, 4 plot
plt.figure(figsize=(20, 6))

# Plot untuk Hemoglobin
plt.subplot(1, 4, 1)  # 1 baris, 4 kolom, plot pertama
sns.boxplot(data=df, x='Result', y='Hemoglobin', hue='Result', palette={'Not Anemic': '#1976D2', 'Anemic': '#B71C1C'})
plt.title('Distribusi Hemoglobin dan Status Anemia')
plt.xlabel('Result')
plt.ylabel('Hemoglobin')

# Plot untuk MCH
plt.subplot(1, 4, 2)  # 1 baris, 4 kolom, plot kedua
sns.boxplot(data=df, x='Result', y='MCH', hue='Result', palette={'Not Anemic': '#1976D2', 'Anemic': '#B71C1C'})
plt.title('Distribusi MCH Berdasarkan Status Anemia')
plt.xlabel('Result')
plt.ylabel('MCH')

# Plot untuk MCV
plt.subplot(1, 4, 3)  # 1 baris, 4 kolom, plot ketiga
sns.boxplot(data=df, x='Result', y='MCV', hue='Result', palette={'Not Anemic': '#1976D2', 'Anemic': '#B71C1C'})
plt.title('Distribusi MCV Berdasarkan Status Anemia')
plt.xlabel('Result')
plt.ylabel('MCV')

# Plot untuk MCHC
plt.subplot(1, 4, 4)  # 1 baris, 4 kolom, plot keempat
sns.boxplot(data=df, x='Result', y='MCHC', hue='Result', palette={'Not Anemic': '#1976D2', 'Anemic': '#B71C1C'})
plt.title('Distribusi MCHC Berdasarkan Status Anemia')
plt.xlabel('Result')
plt.ylabel('MCHC')

# Menyesuaikan layout
plt.tight_layout(pad=2.0)  # Adjust padding between subplots
plt.show()

"""Dapat dilihat bahwa individu yang terkena anemia memiliki kadar hemoglobin lebih rendah dibandingkan dengan individu yang tidak terkena anemia. Sedangkan, fitur MCH, MCV, dan MCHC menunjukkan perbedaan kecil antara kelompok Anemic dan Not Anemic, mengindikasikan bahwa perbedaan yang lebih besar mungkin terletak pada fitur Hemoglobin.

## **Multivariate Analysis**
"""

sns.boxplot(data=df, x='Gender', y='Hemoglobin', hue='Result', palette={'Not Anemic': '#1976D2', 'Anemic': '#B71C1C'})
plt.title('Distribusi Hemoglobin Berdasarkan Gender dan Status Anemia')
plt.show()

"""Pada eksplorasi lebih lanjut, dapat dilihat bahwa perempuan yang menderita anemia (ditandai dengan kotak merah) memiliki kadar Hemoglobin yang lebih rendah dibandingkan dengan laki-laki yang menderita anemia. Selain itu, perempuan yang tidak menderita anemia (kotak biru) menunjukkan kadar Hemoglobin yang lebih tinggi secara keseluruhan dibandingkan laki-laki.

### **Analisis Korelasi**

Fitur Result dan Gender dikembalikan ke tipe data semula (int) karena proses Analisis Distribusi sudah selesai dan pada Analisis Korelasi diperlukan data numerik.
"""

# Ganti nilai pada kolom dengan memetakan kategori menjadi numerik kembali (kembali ke data awal)
df['Gender'] = df['Gender'].replace({'Male': 0, 'Female': 1}).astype(int)
df['Result'] = df['Result'].replace({'Not Anemic': 0, 'Anemic': 1}).astype(int)

# Menghitung matriks korelasi antar fitur numerik pada DataFrame
correlation_matrix = df.corr()

# Visualisasi heatmap matriks korelasi
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, cbar=True)

# Menambahkan judul pada heatmap
plt.title('Matriks Korelasi Antar Fitur')
plt.show()

"""Hemoglobin memiliki korelasi negatif yang kuat dengan Result (-0.80), menunjukkan bahwa semakin rendah kadar hemoglobin, semakin besar kemungkinan seseorang menderita anemia. Kolom Gender menunjukkan korelasi positif yang sangat lemah dengan Result (0.25), sementara korelasi antara fitur-fitur seperti MCH, MCHC, dan MCV dengan Result sangat rendah, menunjukkan bahwa mereka mungkin tidak memberikan kontribusi signifikan dalam memprediksi status anemia. Meskipun begitu tidak akan ada fitur yang dihapus mengingat data yang digunakan sedikit.

# **4. Data Preprocessing**

## **Penghapusan Data Duplikat**

Berdasarkan hasil dari Data Understanding dan EDA, didapatkan bahwa terdapat 887 baris duplikat yang harus dihapus
"""

# Menghapus baris duplikat
df = df.drop_duplicates()
# Memeriksa jumlah baris setelah duplikasi dihapus
print(f"Jumlah baris setelah penghapusan duplikat: {df.shape[0]}")

"""Penghapusan baris duplikat dilakukan dengan *drop_duplicates()* dan sisa data setelah pembersihan baris duplikat adalah 534. Data yang terduplikasi memang cukup banyak, tetapi sisa data yang bersih sebanyak 534 (di atas 500) masih bisa untuk digunakan.

## **Split Dataset**

Mengingat semua fitur pada dateset adalah numerik, maka tidak perlu dilakukan encoding.

Langkah selanjutnya yang perlu dilakukan adalah membagi dataset menjadi data latih (train) dan data uji (test).
"""

# Pisahkan fitur (X) dan target (y)
X = df.drop(columns=['Result'])
y = df['Result'].astype(int)

# Split data menjadi set pelatihan dan set uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Menampilkan jumlah data pada masing-masing set
print("Jumlah data pada X_train:", X_train.shape[0])
print("Jumlah data pada X_test:", X_test.shape[0])
print("Jumlah data pada y_train:", y_train.shape[0])
print("Jumlah data pada y_test:", y_test.shape[0])

# Tampilkan bentuk set pelatihan dan set uji untuk memastikan split
print("\nDistribusi kelas pada data pelatihan:\n", y_train.value_counts())
print("\nDistribusi kelas pada data uji:\n", y_test.value_counts())

"""Data telah dipisahkan menjadi dua set: set pelatihan dan set uji, dengan 80% data digunakan untuk pelatihan dan 20% untuk pengujian. Jumlah data pada set pelatihan (427 data) dan set uji (107 data) telah ditampilkan, memastikan bahwa proporsi data tetap konsisten.

Distribusi kelas pada set pelatihan menunjukkan 229 individu tidak menderita anemia (Result=0) dan 198 individu menderita anemia (Result=1), sedangkan pada set uji, terdapat 58 individu tidak menderita anemia dan 49 individu menderita anemia.

## **Penanganan Imbalance Class**

Pada EDA, diketahui terdapat ketidakseimbangan kelas antara Anemic dan Not Anemic. Oleh karena itu, dilakukan penanganan untuk menyeimbangkan kelas menggunakan SMOTE.
"""

import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE

# Penanganan imbalance class dengan SMOTE (hanya di training set)
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Mengganti label angka dengan kategori
y_train_labels = y_train.map({0: 'Not Anemic', 1: 'Anemic'})
y_train_resampled_labels = y_train_resampled.map({0: 'Not Anemic', 1: 'Anemic'})

# Plot distribusi kelas sebelum SMOTE
plt.figure(figsize=(12, 5))

# Plot pertama untuk sebelum SMOTE
plt.subplot(1, 2, 1)
y_train_labels.value_counts().plot.barh(color=['#1976D2', '#B71C1C'], edgecolor='black')
plt.title('Distribusi Kelas Sebelum SMOTE')
plt.xlabel('Count')
plt.ylabel('Result')

# Plot kedua untuk setelah SMOTE
plt.subplot(1, 2, 2)
y_train_resampled_labels.value_counts().plot.barh(color=['#B71C1C', '#1976D2'], edgecolor='black')
plt.title('Distribusi Kelas Setelah SMOTE')
plt.xlabel('Count')
plt.ylabel('Result')

# Menampilkan plot
plt.tight_layout()
plt.show()

"""Setelah dilakukan SMOTE, dapat terlihat data antara anemic dan not anemic menjadi seimbang.

## **Standarisasi**

Pada tahap ini, dilakukan standarisasi pada data X_train_resampled menggunakan StandardScaler. Proses ini memastikan bahwa setiap fitur dalam data memiliki distribusi dengan rata-rata 0 dan standar deviasi 1.
"""

# Standarisasi data (hanya di training set)
scaler = StandardScaler()

# Fit dan transform data pelatihan
X_train_scaled = scaler.fit_transform(X_train_resampled)

# Transform data uji menggunakan scaler yang sama
X_test_scaled = scaler.transform(X_test)

# Menampilkan contoh data setelah standarisasi
print("Contoh data X_train setelah standarisasi:\n", X_train_scaled[:5])

"""Hasil dari standarisasi terlihat pada output, di mana nilai-nilai fitur yang sebelumnya memiliki rentang berbeda sekarang memiliki skala yang seragam, yang penting untuk model yang sensitif terhadap skala data, seperti KNN.

Setelah melewati tahap data preparation, data siap untuk digunakan dalam pembangunan model

# **5. Pembangunan Model**

## **a. Membangun Model Klasifikasi**

Setiap algoritma klasifikasi dilatih secara terpisah menggunakan data pelatihan. Model RandomForestClassifier, DecisionTreeClassifier, LogisticRegression, KNeighborsClassifier, dikonfigurasi dan dilatih sesuai dengan dataset yang tersedia.
"""

rf = RandomForestClassifier().fit(X_train_scaled, y_train_resampled)
dt = DecisionTreeClassifier().fit(X_train_scaled, y_train_resampled)
lr = LogisticRegression().fit(X_train_scaled, y_train_resampled)
knn = KNeighborsClassifier().fit(X_train_scaled, y_train_resampled)
print("Model training selesai.")

"""Setelah proses pelatihan selesai, model-model ini siap diuji menggunakan data uji. Pesan "Model training selesai." menunjukkan bahwa seluruh model telah berhasil melewati tahap pelatihan dan siap untuk evaluasi.

## **b. Evaluasi Model Klasifikasi**

Kemudian kita melakukan evaluasi awal model sebelum hyperparameter tuning
"""

# Fungsi untuk evaluasi model
def evaluate_model(model, X_test, y_test, model_name):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)  # Confusion matrix

    results = {
        'Confusion Matrix': cm,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred, average='weighted'),
        'Recall': recall_score(y_test, y_pred, average='weighted'),
        'F1-Score': f1_score(y_test, y_pred, average='weighted'),
        'Classification Report': classification_report(y_test, y_pred)
    }

    # Plot Confusion Matrix
    plot_confusion_matrix(cm, model_name)

    return results

# Fungsi untuk menampilkan Confusion Matrix
def plot_confusion_matrix(cm, model_name):
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
    plt.title(f"Confusion Matrix - {model_name}")
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

# Model yang akan diuji
models = {
    'Random Forest (RF)': rf,
    'Decision Tree (DT)': dt,
    'Logistic Regression (LR)': lr,
    'K-Nearest Neighbors (KNN)': knn,
}

# Inisialisasi dictionary hasil evaluasi
results = {}

# Evaluasi semua model
for model_name, model in models.items():
    print(f"\nModel: {model_name}")
    results[model_name] = evaluate_model(model, X_test_scaled, y_test, model_name)
    print(f"Accuracy: {results[model_name]['Accuracy']:.4f}")
    print(f"Precision: {results[model_name]['Precision']:.4f}")
    print(f"Recall: {results[model_name]['Recall']:.4f}")
    print(f"F1-Score: {results[model_name]['F1-Score']:.4f}")
    print("\nClassification Report:")
    print(results[model_name]['Classification Report'])
    print("="*60)

# Buat DataFrame untuk meringkas hasil
summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])

# Isi DataFrame dengan hasil evaluasi
rows = []
for model_name, metrics in results.items():
    rows.append({
        'Model': model_name,
        'Accuracy': metrics['Accuracy'],
        'Precision': metrics['Precision'],
        'Recall': metrics['Recall'],
        'F1-Score': metrics['F1-Score']
    })

# Konversi daftar hasil ke DataFrame
summary_df = pd.DataFrame(rows)

# Tampilkan hasil ringkasan
print(summary_df)

"""Secara keseluruhan, **Random Forest** menjadi model yang paling unggul dalam hal akurasi, recall, dan keseimbangan metrik evaluasi, diikuti oleh **Decision Tree**, **Logistic Regression**, dan **K-Nearest Neighbors**. Model ini memberikan wawasan mengenai fitur yang paling relevan dan memberikan hasil yang optimal pada dataset yang diuji.

## **c. Tuning Model Klasifikasi**

Menggunakan GridSearchCV untuk mencari kombinasi parameter terbaik untuk setiap model dan menyimpannya.

### Random Forest
"""

# Menyiapkan parameter grid untuk tuning RF
param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 20],
    'min_samples_split': [2, 5, 10]
}

# Menyiapkan GridSearchCV
grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5)

# Melakukan fitting GridSearchCV
grid_rf.fit(X_train_scaled, y_train_resampled)

# Menampilkan hasil terbaik
print("Best Params for Random Forest:", grid_rf.best_params_)

# Mendapatkan model terbaik
best_rf = grid_rf.best_estimator_

"""### Decision Tree"""

# Menyiapkan parameter grid untuk tuning DT
param_grid_dt = {
    'max_depth': [3, 5, 10],
    'min_samples_split': [2, 5, 10],
    'criterion': ['gini', 'entropy']
}

# Menyiapkan GridSearchCV
grid_dt = GridSearchCV(DecisionTreeClassifier(), param_grid_dt, cv=5)

# Melakukan fitting GridSearchCV
grid_dt.fit(X_train_scaled, y_train_resampled)

# Menampilkan hasil terbaik
print("Best Params for Decision Tree:", grid_dt.best_params_)

# Mendapatkan model terbaik
best_dt = grid_dt.best_estimator_

"""### Logistic Regression"""

# Menyiapkan parameter grid untuk tuning LR
param_grid_lr = {
    'penalty': ['l1', 'l2'],
    'C': [0.01, 0.1, 1],
    'solver': ['liblinear', 'saga'],
}

# Menyiapkan GridSearchCV
grid_lr = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_lr, cv=5)

# Melakukan fitting GridSearchCV
grid_lr.fit(X_train_scaled, y_train_resampled)

# Menampilkan hasil terbaik
print(f"Best params for Logistic Regression:", grid_lr.best_params_)

# Mendapatkan model terbaik
best_lr = grid_lr.best_estimator_

"""### K-Nearest Neighbors"""

# Menyiapkan parameter grid untuk tuning KNN
param_grid_knn = {
    'n_neighbors': [3, 5, 7],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan']
}

# Menyiapkan GridSearchCV
grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5)

# Melakukan fitting GridSearchCV
grid_knn.fit(X_train_scaled, y_train_resampled)

# Menampilkan hasil terbaik
print("Best Params for KNN:", grid_knn.best_params_)

# Mendapatkan model terbaik
best_knn = grid_knn.best_estimator_

# Menyusun hasil terbaik dalam bentuk summary
results_summary = {
    'Random Forest (RF)': grid_rf.best_params_,
    'Decision Tree (DT)': grid_dt.best_params_,
    'Logistic Regression (LR)': grid_lr.best_params_,
    'K-Nearest Neighbors (KNN)': grid_knn.best_params_
}

# Menampilkan summary hasil best parameters
print("Summary of Best Parameters for Each Model:")
for model_name, best_params in results_summary.items():
    print(f"\n{model_name}:")
    for param, value in best_params.items():
        print(f"  {param}: {value}")

"""## **d. Evaluasi Model Klasifikasi Setelah Tunning**

Setelah menemukan kombinasi parameter terbaik, model dievaluasi ulang untuk melihat perbandingan performa.
"""

# Model yang akan diuji
models = {
    'Random Forest (RF)': best_rf,
    'Decision Tree (DT)': best_dt,
    'Logistic Regression (LR)': best_lr,
    'K-Nearest Neighbors (KNN)': best_knn,
}

# Inisialisasi dictionary hasil evaluasi
results_after_tuning = {}

# Evaluasi semua model
for model_name, model in models.items():
    print(f"\nModel: {model_name}")
    results_after_tuning[model_name] = evaluate_model(model, X_test_scaled, y_test, model_name)
    print(f"Accuracy: {results_after_tuning[model_name]['Accuracy']:.4f}")
    print(f"Precision: {results_after_tuning[model_name]['Precision']:.4f}")
    print(f"Recall: {results_after_tuning[model_name]['Recall']:.4f}")
    print(f"F1-Score: {results_after_tuning[model_name]['F1-Score']:.4f}")
    print("\nClassification Report:")
    print(results_after_tuning[model_name]['Classification Report'])
    print("="*60)

# Buat DataFrame untuk meringkas hasil
summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])

# Isi DataFrame dengan hasil evaluasi
rows = []
for model_name, metrics in results_after_tuning.items():
    rows.append({
        'Model': model_name,
        'Accuracy': metrics['Accuracy'],
        'Precision': metrics['Precision'],
        'Recall': metrics['Recall'],
        'F1-Score': metrics['F1-Score']
    })

# Konversi daftar hasil ke DataFrame
summary_df = pd.DataFrame(rows)

# Tampilkan hasil ringkasan
print(summary_df)

import matplotlib.pyplot as plt

# Hasil evaluasi Recall sebelum tuning
before_tuning_recall = [
    results['Random Forest (RF)']['Recall'],
    results['Decision Tree (DT)']['Recall'],
    results['Logistic Regression (LR)']['Recall'],
    results['K-Nearest Neighbors (KNN)']['Recall']
]

# Hasil evaluasi Recall setelah tuning
after_tuning_recall = [
    results_after_tuning['Random Forest (RF)']['Recall'],
    results_after_tuning['Decision Tree (DT)']['Recall'],
    results_after_tuning['Logistic Regression (LR)']['Recall'],
    results_after_tuning['K-Nearest Neighbors (KNN)']['Recall']
]

# Model names
models = ['Random Forest', 'Decision Tree', 'Logistic Regression', 'KNN']

# Membuat grafik batang untuk perbandingan Recall
x = range(len(models))
fig, ax = plt.subplots(figsize=(10, 6))

# Bar width
bar_width = 0.35

# Plot sebelum tuning
ax.bar(x, before_tuning_recall, bar_width, label='Before Tuning', color='#B71C1C')

# Plot setelah tuning
ax.bar([p + bar_width for p in x], after_tuning_recall, bar_width, label='After Tuning', color='#1976D2')

# Menambahkan judul dan label
ax.set_title('Perbandingan Model: Recall Sebelum dan Sesudah Hyperparameter Tuning')
ax.set_xlabel('Models')
ax.set_ylabel('Recall')
ax.set_xticks([p + bar_width/2 for p in x])
ax.set_xticklabels(models)

# Menambahkan legenda
ax.legend()

# Menampilkan grafik
plt.tight_layout()
plt.show()

"""Ada sedikit peningkatan hasil evaluasi setelah dilakukan hyperparameter tuning

Secara keseluruhan, **Random Forest** tetap menjadi model yang paling disarankan setelah tuning dengan nilai Recall yang sangat tinggi dan metrik evaluasi lainnya yang juga tinggi, diikuti oleh Decision Tree, dengan Logistic Regression dan KNN lebih cocok digunakan dalam skenario yang lebih sederhana. **Recall** yang tinggi sangat diinginkan dalam kasus diagnosis medis, karena **lebih penting** untuk **menangkap semua pasien yang menderita anemia** (mencegah **false negatives**) daripada menghindari beberapa **false positives**. Dalam konteks ini, **false negatives** (pasien yang seharusnya didiagnosis anemia tetapi tidak terdeteksi) dapat berakibat fatal karena pasien tersebut tidak menerima perawatan yang diperlukan. Oleh karena itu, model dengan **Recall** yang lebih tinggi, seperti **Random Forest**, sangat diutamakan untuk memastikan bahwa sebanyak mungkin individu yang menderita anemia dapat terdeteksi dan diberi penanganan yang tepat.


"""